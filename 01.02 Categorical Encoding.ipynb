{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using sklearn libraries\n",
    "2. Using category_encoders - more user friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn_pandas import DataFrameMapper, CategoricalImputer\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer \n",
    "import category_encoders as ce\n",
    "\n",
    "os.chdir('/Users/suma/Documents/01 Data Science/Titanic Problem/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('titanic_train.csv')\n",
    "df_test = pd.read_csv('titanic_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append Train and Test data (for preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_train, df_test]\n",
    "df = pd.concat(frames, axis = 0, sort = False)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible Errors\n",
    "1) When Input field is integer or numerical and you are applying encoding Examaple:PClass <br>\n",
    "2) When there are null values in input fields Example:Embarked <br>\n",
    "3) For label encoding - 1st unique value is mapped to 1, 2nd unique value is mapped to 2 and so on. So for example, unique values are First, Third, Fourth, Tenth, Second... they would be encoded 1, 2, 3, 4, 5 ... This mapping would be wrong for ordinal data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding (sklearn libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "#label encoders work on series data, but not on frames\n",
    "dummy = ['A', 'B', 'C', 'A', 'C']\n",
    "le.fit(dummy)\n",
    "le.classes_\n",
    "le.transform(dummy)\n",
    "\n",
    "le.fit(df['Sex'])\n",
    "print(le.classes_)\n",
    "print(le.transform(df['Sex']))\n",
    "\n",
    "cat_imputer = CategoricalImputer()\n",
    "df['Embarked'] = cat_imputer.fit_transform(df['Embarked'])\n",
    "\n",
    "df[encodable_features] = df[encodable_features].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding (sklearn libraries)\n",
    "##### Method 1: Suitable for complex pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodable_features = ['Pclass','Sex','Embarked']\n",
    "\n",
    "cat_imputer = CategoricalImputer()\n",
    "df['Embarked'] = cat_imputer.fit_transform(df['Embarked'])\n",
    "\n",
    "ct = ColumnTransformer([(\"OneHotEncode\", preprocessing.OneHotEncoder(),encodable_features)], remainder=\"drop\") # The last arg ([0]) is the list of columns you want to transform in this step\n",
    "one_hot_encode_columns = ct.fit_transform(df)\n",
    "new_col_names = []\n",
    "for col in encodable_features:\n",
    "    for s in df[col].unique():\n",
    "        new_col_names.append(col +'_'+ str(s))\n",
    "df_1hot = pd.DataFrame(data = one_hot_encode_columns, columns = new_col_names)\n",
    "df[new_col_names] = df_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Fare Cabin Embarked  Survived  \\\n",
       "0    male  22.0      1      0   7.2500   NaN        S       0.0   \n",
       "1  female  38.0      1      0  71.2833   C85        C       1.0   \n",
       "2  female  26.0      0      0   7.9250   NaN        S       1.0   \n",
       "3  female  35.0      1      0  53.1000  C123        S       1.0   \n",
       "4    male  35.0      0      0   8.0500   NaN        S       0.0   \n",
       "\n",
       "             Ticket  Pclass_3  Pclass_1  Pclass_2  Sex_male  Sex_female  \\\n",
       "0         A/5 21171       0.0       0.0       1.0       0.0         1.0   \n",
       "1          PC 17599       1.0       0.0       0.0       1.0         0.0   \n",
       "2  STON/O2. 3101282       0.0       0.0       1.0       1.0         0.0   \n",
       "3            113803       1.0       0.0       0.0       1.0         0.0   \n",
       "4            373450       0.0       0.0       1.0       0.0         1.0   \n",
       "\n",
       "   Embarked_S  Embarked_C  Embarked_Q  \n",
       "0         0.0         0.0         1.0  \n",
       "1         1.0         0.0         0.0  \n",
       "2         0.0         0.0         1.0  \n",
       "3         0.0         0.0         1.0  \n",
       "4         0.0         0.0         1.0  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method2: Suitable for quick model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = encodable_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Ordinal Encoder (Label Encoder)\n",
    "\n",
    "Sklearn’s LabelEncoder does pretty much the same thing as Category Encoder’s OrdinalEncoder, but is not quite as user friendly. LabelEncoder won’t return a DataFrame, instead it returns a numpy array if you pass a DataFrame. It also outputs values starting with 0, compared to OrdinalEncoder’s default of outputting values starting with 1.\n",
    "\n",
    "You could accomplish ordinal encoding by mapping string values to integers manually with apply. But that’s extra work once you know how to use Category Encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_ord = ce.OrdinalEncoder(cols = 'Pclass')\n",
    "pclass1 = ce_ord.fit_transform(df['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above statement encodes as follows 3 -> 1, 1 -> 2, 2 -> 3, based on first occurance in df. To avoid this follow the below\n",
    "dict = [{'col': 'Pclass', \n",
    "  'mapping': [('1', 1), \n",
    "              ('2', 2), \n",
    "              ('3', 3)]}]\n",
    "\n",
    "ce_ord = ce.OrdinalEncoder(dict)\n",
    "pclass2 = ce_ord.fit_transform(df['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. OneHot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_one_hot = ce.OneHotEncoder(cols = ['Sex','Embarked'])\n",
    "df = ce_one_hot.fit_transform(df)\n",
    "#If a column has null values, then new one hot encoded column would be created for Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Binary Encoder <br>\n",
    "Binary can be thought of as a hybrid of one-hot and hashing encoders. Binary creates fewer features than one-hot, while preserving some uniqueness of values in the the column. It can work well with higher dimensionality ordinal data. <br>\n",
    "\n",
    "- The categories are encoded by OrdinalEncoder if they aren’t already in numeric form. <br>\n",
    "- Then those integers are converted into binary code, so for example 5 becomes 101 and 10 becomes 1010 <br>\n",
    "- Then the digits from that binary string are split into separate columns. So if there are 4–7 values in an ordinal column then 3 new columns are created: one for the first bit, one for the second, and one for the third. <br>\n",
    "- Each observation is encoded across the columns in its binary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_binary = ce.BinaryEncoder(cols = 'Cabin')\n",
    "df = ce_binary.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. BaseN Encoder <br>\n",
    "\n",
    "When the BaseN base = 1 it is basically the same as one hot encoding. When base = 2 it is basically the same as binary encoding. McGinnis said, “Practically, this adds very little new functionality, rarely do people use base-3 or base-8 or any base other than ordinal or binary in real problems.”\n",
    "\n",
    "The main reason for its existence is to possibly make grid searching easier. You could use BaseN with gridsearchCV. However, if you’re going to grid search with some of these encoding options, you’re going to make that search part of your workflow anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_basen = ce.BaseNEncoder(cols = 'Cabin', base = 3)\n",
    "df = ce_basen.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Hashing <br>\n",
    "\n",
    "HashingEncoder implements the hashing trick. It is similar to one-hot encoding but with fewer new dimensions and some info loss due to collisions. The collisions do not significantly affect performance unless there is a great deal of overlap. \n",
    "\n",
    "https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087\n",
    "\n",
    "The n_components parameter controls the number of expanded columns. The default is eight columns. In our example column with three values the default results in five columns full of 0s.\n",
    "\n",
    "If you set n_components less than k you’ll have a small reduction in the value provided by the encoded data. You’ll also have fewer dimensions.\n",
    "\n",
    "You can pass a hashing algorithm of your choice to HashingEncoder; the default is md5. Hashing algorithms have been very successful in some Kaggle competitions. It’s worth trying HashingEncoder for nominal and ordinal data if you have high cardinality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_hash = ce.HashingEncoder(cols = 'Cabin')\n",
    "df = ce_hash.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Target Encoding / Mean Encoding <br>\n",
    "\n",
    "Target encoding is the process of replacing a categorical value with the mean of the target variable.\n",
    "\n",
    "For the case of categorical target: features are replaced with a blend of posterior probability of the target given particular categorical value and the prior probability of the target over all the training data.\n",
    "\n",
    "For the case of continuous target: features are replaced with a blend of the expected value of the target given particular categorical value and the expected value of the target over all the training data.\n",
    "\n",
    "In case of large number of features, mean encoding could prove to be a much simpler alternative\n",
    "\n",
    "Even though it looks like mean encoding is Superman…… it’s kryptonite is overfitting. The fact that we use target classes to encode for our training labels may leak data about the predictions causing the encoding to become biased. Well we can avoid this by Regularizing. Several Kaggle Competitors use mean encoding with regularization to predict much better and rise through ranks in the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_target = ce.TargetEncoder(cols = 'Embarked')\n",
    "df = ce_target.fit_transform(X = df_train, y = df_train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Leave one out encoding\n",
    "\n",
    "This is very similar to target encoding but excludes the current row’s target when calculating the mean target for a level to reduce the effect of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_leave1out = ce.LeaveOneOutEncoder(cols = 'Cabin')\n",
    "df = ce_leave1out.fit_transform(X = df_train, y = df_train['Survived'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
